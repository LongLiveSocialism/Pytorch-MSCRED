{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([5, 32, 30, 30])"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "from utils.data import load_data\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from model.mscred import *\n",
    "\n",
    "dataloader = load_data()\n",
    "for x in dataloader[\"train\"]:\n",
    "    input = x\n",
    "    break\n",
    "input = input[0]\n",
    "\n",
    "class CnnEncoder(nn.Module):\n",
    "    def __init__(self, in_channels_encoder):\n",
    "        super(CnnEncoder, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels_encoder, 32, 3, 1, 1),\n",
    "            nn.SELU()\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3, 2, 1),\n",
    "            nn.SELU()\n",
    "        )    \n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 2, 2, 1),\n",
    "            nn.SELU()\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, 2, 2, 0),\n",
    "            nn.SELU()\n",
    "        )\n",
    "    def forward(self, X):\n",
    "        conv1_out = self.conv1(X)\n",
    "        conv2_out = self.conv2(conv1_out)\n",
    "        conv3_out = self.conv3(conv2_out)\n",
    "        conv4_out = self.conv4(conv3_out)\n",
    "        return conv1_out, conv2_out, conv3_out, conv4_out\n",
    "\n",
    "\n",
    "cnnEncoder = CnnEncoder(3)\n",
    "conv1_out, conv2_out, conv3_out, conv4_out = cnnEncoder(input)\n",
    "conv1_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([5, 32, 30, 30])\ntorch.Size([32, 30, 30])\ntorch.Size([64, 15, 15])\ntorch.Size([128, 8, 8])\ntorch.Size([256, 4, 4])\n"
    }
   ],
   "source": [
    "def attention(ConvLstm_out):\n",
    "    attention_w = []\n",
    "    for k in range(5):\n",
    "        attention_w.append(torch.sum(torch.mul(ConvLstm_out[k], ConvLstm_out[-1]))/5)\n",
    "    m = nn.Softmax(dim=1)\n",
    "    attention_w = torch.reshape(m(torch.stack(attention_w)), (-1, 5))\n",
    "    cl_out_shape = ConvLstm_out.shape\n",
    "    ConvLstm_out = torch.reshape(ConvLstm_out, (5, -1))\n",
    "    convLstmOut = torch.matmul(attention_w, ConvLstm_out)\n",
    "    convLstmOut = torch.reshape(convLstmOut, (1, cl_out_shape[1], cl_out_shape[2], cl_out_shape[3]))\n",
    "    return convLstmOut\n",
    "\n",
    "class Conv_LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Conv_LSTM, self).__init__()\n",
    "        self.conv1_lstm = ConvLSTM(input_channels=32, hidden_channels=[32], \n",
    "                                   kernel_size=3, step=5, effective_step=[4])\n",
    "        self.conv2_lstm = ConvLSTM(input_channels=64, hidden_channels=[64], \n",
    "                                   kernel_size=3, step=5, effective_step=[4])\n",
    "        self.conv3_lstm = ConvLSTM(input_channels=128, hidden_channels=[128], \n",
    "                                   kernel_size=3, step=5, effective_step=[4])\n",
    "        self.conv4_lstm = ConvLSTM(input_channels=256, hidden_channels=[256], \n",
    "                                   kernel_size=3, step=5, effective_step=[4])\n",
    "\n",
    "\n",
    "    def forward(self, conv1_out, conv2_out, \n",
    "                conv3_out, conv4_out):\n",
    "        conv1_lstm_out = self.conv1_lstm(conv1_out)\n",
    "        print(conv1_lstm_out[0][0].shape)\n",
    "        conv1_lstm_out = attention(conv1_lstm_out[0][0])\n",
    "        conv2_lstm_out = self.conv2_lstm(conv2_out)\n",
    "        conv2_lstm_out = attention(conv2_lstm_out[0][0])\n",
    "        conv3_lstm_out = self.conv3_lstm(conv3_out)\n",
    "        conv3_lstm_out = attention(conv3_lstm_out[0][0])\n",
    "        conv4_lstm_out = self.conv4_lstm(conv4_out)\n",
    "        conv4_lstm_out = attention(conv4_lstm_out[0][0])\n",
    "        return conv1_lstm_out.unsqueeze(0), conv2_lstm_out.unsqueeze(0), conv3_lstm_out.unsqueeze(0), conv4_lstm_out.unsqueeze(0)\n",
    "conv_LSTM = Conv_LSTM()\n",
    "\n",
    "conv1_lstm_out, conv2_lstm_out, conv3_lstm_out, conv4_lstm_out = conv_LSTM(\n",
    "                                conv1_out, conv2_out, conv3_out, conv4_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[1, 4],\n        [1, 4]])"
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2]])\n",
    "b = torch.tensor([[1, 2], [1, 2]])\n",
    "torch.mul(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn([5, 32, 30, 30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "5"
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "conv_shape = a.shape[0]\n",
    "conv_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[ 0.6345, -0.9279,  0.9439],\n        [-0.0653, -0.7846, -0.5672]])tensor([[-0.6386, -0.3668, -0.1110],\n        [ 1.5943,  0.4609, -1.0188]])\ntensor([[-0.4051,  0.3403, -0.1048],\n        [-0.1042, -0.3616,  0.5779]])\n"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}